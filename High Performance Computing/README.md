This course is an introduction to parallel computing and programming. Topics include, but are not
exclusively limited to:

• Introduction and Motivation: Amdahl’s Law, and review of uni-processor memory and CPU
organization.

• Parallel architectures: Message passing, shared-memory system, vector/SIMD and communications
networks.

• Parallel Programming: Message Passing Interface (MPI), Pthreads, OpenMP, CUDA.
• Parallel Filesystems: MPI File interface.
• Performance Analysis Tools: Tau.
• Partitioned Global Address Languages: UPC and ZPL.
• Other Parallel Programming Paradigms: MapReduce, Transactional Memory.
• Fault Tolerance
• Applications: Computational Fluid Dynamics, Mesh Adaptivity and Parallel Discrete-Event
Simulation, Electronic Design Automation.
